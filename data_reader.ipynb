{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1JLQ7uEm3AUmErGsyI9AOxC-_6pE2Wzco",
      "authorship_tag": "ABX9TyNdxZxwr2Weli15pIfnMcBr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raspberryscorn/4_11_3/blob/main/data_reader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNzw6hWftlIA"
      },
      "outputs": [],
      "source": [
        "cd \"/content/drive/MyDrive/ddeep/bhban_ai/SECTION_4/Chapter_11/4_11_1\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Author : Byunghyun Ban\n",
        "Date : 2020.07.17.\n",
        "\"\"\"\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "from tensorflow import keras\n",
        "import random\n",
        "\n",
        "import time\n",
        "\n",
        "try:\n",
        "    from matplotlib import pyplot as plt\n",
        "except ModuleNotFoundError:\n",
        "    import pip\n",
        "    pip.main(['install', 'matplotlib'])\n",
        "    try:\n",
        "        from matplotlib import pyplot as plt\n",
        "    except ModuleNotFoundError:\n",
        "        time.sleep(2)\n",
        "        from matplotlib import pyplot as plt\n",
        "\n",
        "try:\n",
        "    import numpy as np\n",
        "except ModuleNotFoundError:\n",
        "    import pip\n",
        "    pip.main(['install', 'numpy'])\n",
        "    try:\n",
        "        import numpy as np\n",
        "    except ModuleNotFoundError:\n",
        "        time.sleep(2)\n",
        "        import numpy as np\n",
        "\n",
        "\n",
        "# 데이터를 떠먹여 줄 클래스를 제작합니다.\n",
        "class DataReader():\n",
        "    def __init__(self):\n",
        "        self.train_X, self.train_Y, self.test_X, self.test_Y = self.read_data()\n",
        "\n",
        "        # 데이터 읽기가 완료되었습니다.\n",
        "        # 읽어온 데이터의 정보를 출력합니다.\n",
        "        print(\"\\n\\nData Read Done!\")\n",
        "        print(\"Training X Size : \" + str(self.train_X.shape))\n",
        "        print(\"Training Y Size : \" + str(self.train_Y.shape))\n",
        "        print(\"Test X Size : \" + str(self.test_X.shape))\n",
        "        print(\"Test Y Size : \" + str(self.test_Y.shape) + '\\n\\n')\n",
        "\n",
        "    def read_data(self):\n",
        "        filename = \"data/\" + os.listdir(\"data\")[0]\n",
        "        file = open(filename)\n",
        "        data = []\n",
        "\n",
        "        for line in file:\n",
        "            splt = line.split(\"\\t\")\n",
        "            if splt[0] == \"ham\":\n",
        "                y = 0.0\n",
        "            elif splt[0] == \"spam\":\n",
        "                y = 1.0\n",
        "\n",
        "            x = splt[1].strip()\n",
        "            if (x, y) not in data:\n",
        "                data.append((x, y))\n",
        "\n",
        "        random.shuffle(data)\n",
        "\n",
        "        X = []\n",
        "        Y = []\n",
        "\n",
        "        for el in data:\n",
        "            X.append(el[0])\n",
        "            Y.append(el[1])\n",
        "\n",
        "        Y = np.asarray(Y)\n",
        "\n",
        "        tokenizer = keras.preprocessing.text.Tokenizer()\n",
        "        tokenizer.fit_on_texts(X)\n",
        "        X = tokenizer.texts_to_sequences(X)\n",
        "        X = keras.preprocessing.sequence.pad_sequences(X, value=0, padding='post', maxlen=189)\n",
        "\n",
        "        train_X = X[:int(0.8*len(X))]\n",
        "        train_Y = Y[:int(0.8*len(Y))]\n",
        "        test_X = X[int(0.8*len(X)):]\n",
        "        test_y = Y[int(0.8*len(Y)):]\n",
        "\n",
        "        return train_X, train_Y, test_X, test_y\n",
        "\n",
        "\n",
        "def draw_graph(history):\n",
        "    train_history = history.history[\"loss\"]\n",
        "    validation_history = history.history[\"val_loss\"]\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        "    plt.title(\"Loss History\")\n",
        "    plt.xlabel(\"EPOCH\")\n",
        "    plt.ylabel(\"LOSS Function\")\n",
        "    plt.plot(train_history, \"red\")\n",
        "    plt.plot(validation_history, 'blue')\n",
        "    fig.savefig(\"train_history.png\")\n",
        "\n",
        "    train_history = history.history[\"accuracy\"]\n",
        "    validation_history = history.history[\"val_accuracy\"]\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        "    plt.title(\"Accuracy History\")\n",
        "    plt.xlabel(\"EPOCH\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.plot(train_history, \"red\")\n",
        "    plt.plot(validation_history, 'blue')\n",
        "    fig.savefig(\"accuracy_history.png\")\n"
      ],
      "metadata": {
        "id": "1XSzN_sOtxGt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}